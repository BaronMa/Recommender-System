{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rs_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dAQpYjPVzdsw"
      },
      "source": [
        "# Recommendation Systems Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GUjvLryBzdsx"
      },
      "source": [
        "### MIE451/1513 UofT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T8rWqpOEzdsz"
      },
      "source": [
        "### Getting MovieLens data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PQaV4DkBzds0"
      },
      "source": [
        "* Download the movielens 100k dataset from this link: [ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)\n",
        "\n",
        "* Upload ml-100k.zip\n",
        "\n",
        "* Extract using the following cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9dHQTK1zds1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xncf3xm1zds2",
        "outputId": "65b3bd3d-87ea-4634-dff0-2145a20e49b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "# np.seterr(divide='ignore', invalid='ignore')\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from heapq import nlargest\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import wget"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1ill6yOzds5"
      },
      "source": [
        "## Support functions and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNbQGMevzds8",
        "outputId": "40c69140-84ba-428a-e587-4f832e3a9e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/ml-100k.zip\")\n",
        "!unzip ml-100k.zip\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "emOWqsTGzdtB",
        "outputId": "9551a7d7-ef8a-43e0-9726-8e4c7899c2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls {MOVIELENS_DIR}"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3k0-kPF7zdtE",
        "colab": {}
      },
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nvqWuW5NzdtI",
        "colab": {}
      },
      "source": [
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5RPCAd--22MQ",
        "outputId": "fd27b659-c682-4294-b114-c129ad1cda52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SpmN2NrTzdtK",
        "outputId": "4aba23a7-f8b0-4c2e-9a8c-97a61cea9288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_users = len(rating_df.userID.unique())\n",
        "num_items = len(rating_df.itemID.unique())\n",
        "print(\"Number of users:\", num_users)\n",
        "print(\"Number of items:\", num_items)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of items: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GQg7fW9SzdtO"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jLVaLm25zdtO"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FiiG_0QfzdtP",
        "colab": {}
      },
      "source": [
        "def dataPreprocessor(rating_df, num_users, num_items):\n",
        "    \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "            \n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array. \n",
        "            \n",
        "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
        "            \n",
        "        NOTE 2: data can have more columns, but your function should ignore \n",
        "              additional columns.\n",
        "    \"\"\"\n",
        "    ########### your code goes here ###########\n",
        "    # Initialize a of size (numUsers, numItems) to zeros\n",
        "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
        "    \n",
        "    # Populate the matrix based on the dataset\n",
        "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
        "        matrix[userID-1, itemID-1] = rating\n",
        "    ###########         end         ###########\n",
        "    return matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f6DxbgBmzdtS",
        "outputId": "edefa687-d64a-4751-bc5b-f0b0946d021b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dataPreprocessor(rating_df, num_users, num_items)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 4, ..., 0, 0, 0],\n",
              "       [4, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [5, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 5, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4b4XZHBczdtU"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z9AkrRvUzdtV",
        "colab": {}
      },
      "source": [
        "class BaseLineRecSys(object):\n",
        "    def __init__(self, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            method: string. From ['popularity','useraverage']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.method_name\n",
        "        \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'popularity': self.popularity,\n",
        "            'useraverage': self.useraverage,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def useraverage(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            #if rating == 0:\n",
        "            # select the row for user\n",
        "            # what's the shape of userVector\n",
        "            userVector = train_matrix[user, :]\n",
        "            \n",
        "            # Extract the items the user already rated\n",
        "            ratedItems = userVector[userVector.nonzero()]\n",
        "            \n",
        "            # If not empty, calculate average and set as rating for the current item\n",
        "            if ratedItems.size == 0:\n",
        "                itemAvg = 0\n",
        "            else:\n",
        "                itemAvg = ratedItems.mean()\n",
        "            predictionMatrix[user, item] = itemAvg\n",
        "            \n",
        "            # report progress every 100 users\n",
        "            if (user % 100 == 0 and item == 1):\n",
        "                print (\"calculated %d users\" % (user,))\n",
        "\n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def popularity(train_matrix, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                train_matrix: 2D numpy array.\n",
        "                num_users: int. Number of Users.\n",
        "                num_items: int. Number of Items.\n",
        "            OUTPUT:\n",
        "                predictionMatrix: 2D numpy array.\n",
        "                \n",
        "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
        "        \"\"\"\n",
        "        \n",
        "        predictionMatrix = np.zeros((num_users, num_items))\n",
        "        ########### your code goes here ###########\n",
        "        # Initialize the predicted rating matrix with zeros\n",
        "    \n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "    \n",
        "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
        "        itemPopularity = np.zeros((num_items))\n",
        "        for item in range(num_items):\n",
        "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
        "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
        "            if numOfUsersRated == 0:\n",
        "                itemPopularity[item] = 0\n",
        "            else:\n",
        "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
        "    \n",
        "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
        "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
        "            #if rating == 0:\n",
        "            predictionMatrix[user, item] = itemPopularity[item]\n",
        "            \n",
        "            # report progress every 100 users\n",
        "            if (user % 100 == 0 and item == 1):\n",
        "                print (\"calculated %d users\" % (user,))\n",
        "\n",
        "     \n",
        "        ###########         end         ###########\n",
        "        return predictionMatrix    \n",
        "    \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        self.__model = self.method(train_matrix, num_users, num_items)\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "            \n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "\n",
        "        return prediction\n",
        "        \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You don not have model..\")\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XgDw3ALnzdtX",
        "colab": {}
      },
      "source": [
        "popularity_recsys = BaseLineRecSys('popularity')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJd50FSdzdta",
        "outputId": "1217ad20-a318-46fd-deef-ae9dea6ddf68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "popularity_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5TJkUaszdtc",
        "colab": {}
      },
      "source": [
        "x = popularity_recsys.getModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HN8r3Obtzdtg",
        "outputId": "8648e8ea-2fd2-4995-c5cb-6c9497623ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.all(x<=1)"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oZDsDg5Gzdtj",
        "outputId": "88599ad0-164c-4912-fb3a-040469d141b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p60BEmn-zdtm",
        "outputId": "84362ae1-3562-4a39-df53-c77d6c461804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:24, 1179.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>0.760684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>0.804714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>0.611111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  popularity\n",
              "0     196     242       3  881250949    0.760684\n",
              "1     186     302       3  891717742    0.804714\n",
              "2      22     377       1  878887116    0.076923\n",
              "3     244      51       2  880606923    0.555556\n",
              "4     166     346       1  886397596    0.611111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xDu_THj3zdtp",
        "colab": {}
      },
      "source": [
        "average_user_rating_recsys = BaseLineRecSys('useraverage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQWmspQGzdtr",
        "outputId": "3210cadc-88f0-4ee5-9285-7f4b5edde0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yl8uLyIqzdty",
        "outputId": "aa1cd47d-e7cb-4dfc-a450-7293d91cb9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "average_user_rating_recsys.getModel()"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.61029412, 3.61029412, 3.61029412, ..., 3.61029412, 3.61029412,\n",
              "        3.61029412],\n",
              "       [3.70967742, 3.70967742, 3.70967742, ..., 3.70967742, 3.70967742,\n",
              "        3.70967742],\n",
              "       [2.7962963 , 2.7962963 , 2.7962963 , ..., 2.7962963 , 2.7962963 ,\n",
              "        2.7962963 ],\n",
              "       ...,\n",
              "       [4.04545455, 4.04545455, 4.04545455, ..., 4.04545455, 4.04545455,\n",
              "        4.04545455],\n",
              "       [4.26582278, 4.26582278, 4.26582278, ..., 4.26582278, 4.26582278,\n",
              "        4.26582278],\n",
              "       [3.41071429, 3.41071429, 3.41071429, ..., 3.41071429, 3.41071429,\n",
              "        3.41071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "arSCkkxozdt4",
        "outputId": "a6b6e1f6-db88-4085-a3c0-f49f7dd8f992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:24, 1181.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>useraverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>3.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>3.413043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>3.351562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>3.651261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>3.550000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  useraverage\n",
              "0     196     242       3  881250949     3.615385\n",
              "1     186     302       3  891717742     3.413043\n",
              "2      22     377       1  878887116     3.351562\n",
              "3     244      51       2  880606923     3.651261\n",
              "4     166     346       1  886397596     3.550000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u_RlOlrIzdt7"
      },
      "source": [
        "## Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I4zY0XYDzdt7"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GEQ_IkS3zdt8",
        "colab": {}
      },
      "source": [
        "class SimBasedRecSys(object):\n",
        "\n",
        "    def __init__(self, base, method, processor=dataPreprocessor):\n",
        "        \"\"\"\n",
        "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
        "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
        "            processor: function name. dataPreprocessor by default\n",
        "        \"\"\"\n",
        "        self.base = base\n",
        "        self.method_name = method\n",
        "        self.method = self._getMethod(self.method_name)\n",
        "        self.processor = processor\n",
        "        self.pred_column_name = self.base+'-'+self.method_name\n",
        "    \n",
        "    def _getMethod(self, method_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'cosine': self.cosine,\n",
        "            'euclidean': self.euclidean,\n",
        "            'somethingelse': self.somethingelse,\n",
        "        }\n",
        "        \n",
        "        return switcher[method_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def cosine(matrix):\n",
        "        \"\"\"\n",
        "            cosine similarity\n",
        "        \"\"\"\n",
        "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def euclidean(matrix):\n",
        "        \"\"\"\n",
        "            euclidean similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        similarity_matrix = 1/(1 + pairwise_distances(matrix, metric='euclidean'))\n",
        "    \n",
        "        ###########         end         ###########    \n",
        "        \n",
        "        return similarity_matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def somethingelse(matrix):\n",
        "        \"\"\"\n",
        "            manhattan? or super-natural intuition similarity\n",
        "        \"\"\"\n",
        "        ########### your code goes here ###########\n",
        "        similarity_matrix = 1/(1 + pairwise_distances(matrix, metric='manhattan'))\n",
        "        # Implement an additional third metric Manhattan.\n",
        "    \n",
        "        ###########         end         ###########        \n",
        "        return similarity_matrix\n",
        "        \n",
        "    def predict_all(self, train_df, num_users, num_items):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_row: scalar. number of users\n",
        "                num_col: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method assigns the result to self.model\n",
        "            \n",
        "            NOTES:\n",
        "                self.__model should contain predictions for *all* user and items\n",
        "                (don't worry about predicting for observed (user,item) pairs,\n",
        "                 since we won't be using these predictions in the evaluation)\n",
        "                (see code in for an efficient vectorized example)\n",
        "        \"\"\"\n",
        "        train_matrix = self.processor(train_df, num_users, num_items)\n",
        "        \n",
        "        if self.base == 'user':\n",
        "            ########### your code goes here ###########\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            uu_similarity = self.method(train_matrix) \n",
        "            normalizer = np.matmul(uu_similarity, temp_matrix) # UU * UI = UI\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            predictionMatrix = np.matmul(uu_similarity, train_matrix)/normalizer\n",
        "\n",
        "            temp_matrix[temp_matrix == 0] = 1e-5\n",
        "            useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
        "            self.__model = predictionMatrix\n",
        "            ###########         end         ###########\n",
        "            \n",
        "        elif self.base == 'item':\n",
        "            ########### your code goes here ###########\n",
        "            train_matrix = train_matrix.T\n",
        "            temp_matrix = np.zeros(train_matrix.shape)\n",
        "            temp_matrix[train_matrix.nonzero()] = 1\n",
        "            ii_similarity = self.method(train_matrix)\n",
        "            normalizer = np.matmul(ii_similarity, temp_matrix) # II * IU = IU\n",
        "            normalizer[normalizer == 0] = 1e-5\n",
        "            predictionMatrix = np.matmul(ii_similarity, train_matrix)/normalizer\n",
        "\n",
        "            temp_matrix[temp_matrix == 0] = 1e-5\n",
        "            itemaverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
        "            columns = np.sum(predictionMatrix, axis=0)\n",
        "            predictionMatrix[:, columns==0] = predictionMatrix[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
        "            self.__model = predictionMatrix.T\n",
        "            ###########         end         ###########\n",
        "        else:\n",
        "            print('No other option available')\n",
        "        \n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "            NOTE: 1. data can have more columns, but your function should ignore \n",
        "                  additional columns.\n",
        "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
        "                  if base == 'user' and method == 'cosine', \n",
        "                  then base-method == 'user-cosine'\n",
        "                  3. your predictions go to 'base-method' column\n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = test_df.copy()\n",
        "        else:\n",
        "            prediction = test_df\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def getModel(self):\n",
        "        \"\"\"\n",
        "            return predicted user-item matrix\n",
        "        \"\"\"\n",
        "        return self.__model\n",
        "    \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.model = None\n",
        "        except:\n",
        "            print(\"You do not have model..\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RROHVWRpzduA",
        "outputId": "f3302148-0b2c-4fea-902c-0db5c10fa9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Examples of how to call similarity functions.\n",
        "I = np.eye(3)\n",
        "SimBasedRecSys.cosine(I)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQ5BkzGPzduC",
        "outputId": "fc1eb2fe-1e58-4f29-95ac-281dceafe269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "SimBasedRecSys.euclidean(I)"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.41421356, 0.41421356],\n",
              "       [0.41421356, 1.        , 0.41421356],\n",
              "       [0.41421356, 0.41421356, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2V-L-T-PzduF",
        "outputId": "06dd1fb1-2e31-4510-b74b-bdd60fdf5443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "SimBasedRecSys.somethingelse(I)"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33333333, 0.33333333],\n",
              "       [0.33333333, 1.        , 0.33333333],\n",
              "       [0.33333333, 0.33333333, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhTgLA5R1Ky0",
        "colab_type": "text"
      },
      "source": [
        "From the example, we can see that **cosine similarity** works better.<br>\n",
        "Since euclidean distance calculates the distance between two points while the **cosine similarity calculates the angle** between two vectors. It is easy to know that Euclidean distance is a worse idea because Euclidean distance is large for vectors of different lengths even though they are in the same direction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "USPsbXpnzduH"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-n9vfzo6-4i",
        "colab_type": "text"
      },
      "source": [
        "Sometimes we use Euclidean or Manhattan Distance just because they are easy to utilize, calculate and explain intuitively. Manhattan distance (L1 norm) may be preferable to Euclidean distance (L2 norm) for the case of high dimensional data; If you want to place less emphasis on outliers, manhattan distance will try to reduce all errors equally since the gradient has constant magnitude.<br>\n",
        "Reference: https://datascience.stackexchange.com/questions/20075/when-would-one-use-manhattan-distance-as-opposite-to-euclidean-distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qDrJogepzduL"
      },
      "source": [
        "## Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Ju9mZE9zduM"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zAaSIC3BzduM",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys = SimBasedRecSys('user','cosine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBGVr2_JzduQ",
        "colab": {}
      },
      "source": [
        "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "isW4B7nfzduW",
        "outputId": "a4070ec4-ee8e-47c5-d516-670f1fb9bf57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "user_cosine_recsys.getModel()"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.89911175, 3.19022667, 3.0261129 , ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.84034456, 3.17139889, 2.92626717, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.87104065, 3.12823798, 3.03250708, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       ...,\n",
              "       [3.90754645, 3.20227238, 3.05776201, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91100649, 3.21591021, 2.98854017, ..., 2.        , 3.        ,\n",
              "        3.        ],\n",
              "       [3.91593122, 3.24268207, 3.08255897, ..., 0.        , 3.        ,\n",
              "        3.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wdxjAZJrzdud",
        "outputId": "357320f0-e6b6-4e0f-f1d0-b06d9a308805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242       3  881250949\n",
              "1     186     302       3  891717742\n",
              "2      22     377       1  878887116\n",
              "3     244      51       2  880606923\n",
              "4     166     346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yc2PgKylzdug",
        "outputId": "52177eac-1b85-4155-a998-d0abf065637f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:24, 1188.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user-cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>4.025213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>4.142828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>1.922080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>3.431884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>3.424963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  user-cosine\n",
              "0     196     242       3  881250949     4.025213\n",
              "1     186     302       3  891717742     4.142828\n",
              "2      22     377       1  878887116     1.922080\n",
              "3     244      51       2  880606923     3.431884\n",
              "4     166     346       1  886397596     3.424963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Ic_FKWUzdui",
        "outputId": "faea6275-79d8-4af0-ea97-1b9f808b116c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
        "item_cosine_recsys.predict_all(rating_df, num_users, num_items)\n",
        "item_cosine_recsys.getModel()"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.75429099, 3.66419957, 3.73222997, ..., 3.60248287, 3.79662696,\n",
              "        3.90232044],\n",
              "       [3.83658867, 3.80424519, 3.77473905, ..., 3.72798332, 3.9109779 ,\n",
              "        3.79775927],\n",
              "       [2.84492718, 2.89389328, 2.84327324, ..., 2.99504451, 3.16444153,\n",
              "        2.9858119 ],\n",
              "       ...,\n",
              "       [4.11427954, 4.0558267 , 4.00963139, ..., 4.        , 3.87872799,\n",
              "        4.14814803],\n",
              "       [4.37096823, 4.39679254, 4.33543016, ..., 3.955358  , 4.41891089,\n",
              "        4.57995134],\n",
              "       [3.52030345, 3.46948821, 3.52393064, ..., 0.        , 3.6110641 ,\n",
              "        3.59656861]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcXFQe2e0dki",
        "colab_type": "code",
        "outputId": "bbd7fb16-30ec-4e5e-d1d7-7dc172f07414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "itemcos = item_cosine_recsys.evaluate_test(rating_df,copy=True)"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:23, 1194.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zULfjYM_3Y_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "949accd1-5399-4650-dcf6-8fb82e6e3545"
      },
      "source": [
        "itemcos.head()"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>item-cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "      <td>3.591314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "      <td>3.344077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "      <td>2.965365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "      <td>3.637332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "      <td>3.333013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp  item-cosine\n",
              "0     196     242       3  881250949     3.591314\n",
              "1     186     302       3  891717742     3.344077\n",
              "2      22     377       1  878887116     2.965365\n",
              "3     244      51       2  880606923     3.637332\n",
              "4     166     346       1  886397596     3.333013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP8SfD2f5HxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4b9c61e-d1ce-4604-8de9-1baee64048fe"
      },
      "source": [
        "any(itemcos['item-cosine'].isnull())"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pZdTvp_szduk"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-BnXbsLzdul",
        "colab": {}
      },
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "    \n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eJKyb9l-zdun",
        "colab": {}
      },
      "source": [
        "# How to use CrossValidation Class?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CU3rZPtnzdus",
        "colab": {}
      },
      "source": [
        "# 1. gather your algorithms in previous steps.\n",
        "# algorithm_instances = [popularity_recsys, \n",
        "#                        average_user_rating_recsys, \n",
        "#                        user_cosine_recsys]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xf-m7d5Dzdux",
        "colab": {}
      },
      "source": [
        "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
        "# RMSE, P@K, R@K\n",
        "# Precision at K in this example\n",
        "# cv_patk = CrossValidation('P@K')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqcihyZdzduz",
        "colab": {}
      },
      "source": [
        "# 3. Run CV by giving:\n",
        "#    1> algorithms just gathered\n",
        "#    2> number of users in the full dataset\n",
        "#    3> number of items in the full dataset\n",
        "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
        "# Results include independent results from 5 folds, their mean, and confidence interval.\n",
        "# cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGgJqyAb8NwE",
        "colab_type": "code",
        "outputId": "7f1f9ba9-00ca-4f1f-a977-91c13acba1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "algorithm_instances = [item_cosine_recsys, \n",
        "                       user_cosine_recsys]\n",
        "cv_RMSE = CrossValidation('RMSE')\n",
        "results = cv_RMSE.run(algorithm_instances, num_users, num_items,k=5)"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:10, 1982.78it/s]\n",
            "20000it [00:09, 2112.68it/s]\n",
            "20000it [00:09, 2156.89it/s]\n",
            "20000it [00:09, 2117.38it/s]\n",
            "20000it [00:09, 2095.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2098.70it/s]\n",
            "20000it [00:09, 2083.82it/s]\n",
            "20000it [00:09, 2098.35it/s]\n",
            "20000it [00:09, 2127.58it/s]\n",
            "20000it [00:09, 2098.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3KoU_9r87k4",
        "colab_type": "code",
        "outputId": "4fe9f52b-2359-4469-ffb2-03673aa4c07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"The average and 95% CI of RMSE results for item-cosine is : [{:.4f}, {}]\".format(results['item-cosine'][1],results['item-cosine'][2:4]))\n",
        "print(\"The average and 95% CI of RMSE results for user-cosine is : [{:.4f}, {}]\".format(results['user-cosine'][1],results['user-cosine'][2:4]))"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average and 95% CI of RMSE results for item-cosine is : [1.0201, [1.0068242686250732, 1.0333415315874226]]\n",
            "The average and 95% CI of RMSE results for user-cosine is : [1.0174, [1.009012742074572, 1.0256949036108092]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlpmbBdA9Ay-",
        "colab_type": "text"
      },
      "source": [
        "**User-cosine similarity performs better** not only for the mean rmse, but for the tighter 95CI. <br>\n",
        "From Q1, number of users is 943 and number of items is 1682, that's to say, **the average ratings per user is higher than average ratings per item**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nJCFpLY25JuY"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RMdW5aLG5OTH"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AI1hS4CP5RVP",
        "colab": {}
      },
      "source": [
        "class PMFRecSys(object):\n",
        "    def __init__(self, num_feat=10, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
        "        \"\"\"\n",
        "            num_feat: int, number of latent features\n",
        "            epsilon: float, learning rate\n",
        "            _lambda: float, L2 regularization,\n",
        "            momentum: float, momentum of the gradient,\n",
        "            maxepoch: float, Number of epoch before stop,\n",
        "            num_batches: int, Number of batches in each epoch (for SGD optimization),\n",
        "            batch_size:Number int, of training samples used in each batches (for SGD optimization)\n",
        "            \n",
        "        \"\"\"\n",
        "        self.num_feat = num_feat  # Number of latent features,\n",
        "        self.epsilon = epsilon  # learning rate,\n",
        "        self._lambda = _lambda  # L2 regularization,\n",
        "        self.momentum = momentum  # momentum of the gradient,\n",
        "        self.maxepoch = maxepoch  # Number of epoch before stop,\n",
        "        self.num_batches = num_batches  # Number of batches in each epoch (for SGD optimization),\n",
        "        self.batch_size = batch_size  # Number of training samples used in each batches (for SGD optimization)\n",
        "        self.test = False\n",
        "        self.w_Item = None  # Item feature vectors\n",
        "        self.w_User = None  # User feature vectors\n",
        "        \n",
        "        self.rmse_train = []\n",
        "        self.rmse_test = []\n",
        "        self.pred_column_name='PMF'\n",
        "\n",
        "    def predict_all(self, train_vec, num_user, num_item):\n",
        "        \"\"\"\n",
        "            INPUT: \n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "                num_user: scalar. number of users\n",
        "                num_item: scalar. number of items\n",
        "            OUTPUT:\n",
        "                no return... this method update w_User and w_Item\n",
        "            \n",
        "            NOTES:\n",
        "                self.W_Item and self.W_User are use to do the final predition for a user\n",
        "                \n",
        "        \"\"\"\n",
        "        # select 'userID', 'itemID', 'rating only\n",
        "        train_vec = train_vec.iloc[:, :3].values\n",
        "        if self.test:\n",
        "          train_vec, val_vec = train_test_split(train_vec)\n",
        "          pairs_val = val_vec.shape[0]\n",
        "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
        "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
        "        pairs_train = train_vec.shape[0]  # num of rating\n",
        "        \n",
        "\n",
        "        # to avoid out of bound\n",
        "        num_user += 1  \n",
        "        num_item += 1  \n",
        "        # initialize\n",
        "        self.epoch = 0\n",
        "        \n",
        "        ########### your code goes here ###########\n",
        "    \n",
        "        self.w_Item = np.random.normal(0, 0.1, (num_item, self.num_feat))   # item M x D \n",
        "        self.w_User = np.random.normal(0, 0.1, (num_user, self.num_feat))  # user N x D \n",
        "    \n",
        "    \n",
        "        ###########         end         ###########  \n",
        "\n",
        "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
        "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
        "        while self.epoch < self.maxepoch: \n",
        "            self.epoch += 1\n",
        "\n",
        "            # Shuffle training truples\n",
        "            shuffled_order = np.arange(train_vec.shape[0])  \n",
        "            np.random.shuffle(shuffled_order)  #shuffled\n",
        "\n",
        "            # Batch update\n",
        "            for batch in range(self.num_batches): \n",
        "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
        "\n",
        "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
        "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
        "\n",
        "\n",
        "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
        "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating  \n",
        "                ########### your code goes here ###########\n",
        "            \n",
        "                pred_out = np.sum(np.multiply(self.w_User[batch_UserID,:],self.w_Item[batch_ItemID,:]), axis = 1) #size (batch_size, )\n",
        "            \n",
        "            \n",
        "                ###########         end         ########### \n",
        "\n",
        "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
        "\n",
        "                # Compute gradients\n",
        "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
        "                       + self._lambda * self.w_User[batch_UserID, :]\n",
        "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
        "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
        "\n",
        "                dw_Item = np.zeros((num_item, self.num_feat))\n",
        "                dw_User = np.zeros((num_user, self.num_feat))\n",
        "\n",
        "                # loop to aggreate the gradients of the same element\n",
        "                for i in range(self.batch_size):\n",
        "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
        "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
        "\n",
        "                # Update with momentum\n",
        "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
        "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
        "\n",
        "                self.w_Item = self.w_Item - self.w_Item_inc\n",
        "                self.w_User = self.w_User - self.w_User_inc\n",
        "\n",
        "                # Compute Compute mean rating subtracted rating \n",
        "                if batch == self.num_batches - 1:\n",
        "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
        "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[train_user_idx,:],self.w_Item[train_item_idx,:]), axis = 1) # size(pairs_train, )\n",
        "            \n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2] \n",
        "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
        "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
        "\n",
        "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
        "\n",
        "                # Compute validation error\n",
        "                if batch == self.num_batches - 1 and self.test:\n",
        "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
        "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
        "                    ########### your code goes here ###########\n",
        "            \n",
        "                    pred_out = np.sum(np.multiply(self.w_User[val_user_idx,:],self.w_Item[val_item_idx,:]), axis = 1) #size(pairs_val, )\n",
        "            \n",
        "            \n",
        "                    ###########         end         ########### \n",
        "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
        "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
        "\n",
        "\n",
        "    def evaluate_test(self, test_df, copy=False):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
        "            OUTPUT:\n",
        "                predictions:  pandas DataFrame. \n",
        "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
        "                              \n",
        "        \"\"\"\n",
        "        if copy:\n",
        "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
        "        else:\n",
        "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
        "        prediction[self.pred_column_name] = np.nan\n",
        "        \n",
        "        for (index, \n",
        "             userID, \n",
        "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
        "            prediction.loc[index, self.pred_column_name] = (np.dot(self.w_Item, self.w_User[int(userID), :]) + self.mean_rating_train)[int(itemID)]\n",
        "    \n",
        "        return prediction\n",
        "    \n",
        "    def plot_error(self):\n",
        "      if self.test:\n",
        "        plt.plot(range(pmf.maxepoch), pmf.rmse_test, marker='v', label='Test Data')\n",
        "      plt.plot(range(pmf.maxepoch), pmf.rmse_train, marker='o', label='Training Data')\n",
        "      plt.title('The MovieLens Dataset Learning Curve')\n",
        "      plt.xlabel('Number of Epochs')\n",
        "      plt.ylabel('RMSE')\n",
        "      plt.legend()\n",
        "      plt.grid()\n",
        "      plt.show()\n",
        "          \n",
        "    def getPredColName(self):\n",
        "        \"\"\"\n",
        "            return prediction column name\n",
        "        \"\"\"\n",
        "        return self.pred_column_name\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            reuse the instance of the class by removing model\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.w_Item = None \n",
        "            self.w_User = None \n",
        "        except:\n",
        "            print(\"You do not have w_Item, w_User\")\n",
        "\n",
        "    def set_params(self, parameters):\n",
        "        if isinstance(parameters, dict):\n",
        "            self.num_feat = parameters.get(\"num_feat\", 10)\n",
        "            self.epsilon = parameters.get(\"epsilon\", 1)\n",
        "            self._lambda = parameters.get(\"_lambda\", 0.1)\n",
        "            self.momentum = parameters.get(\"momentum\", 0.8)\n",
        "            self.maxepoch = parameters.get(\"maxepoch\", 20)\n",
        "            self.num_batches = parameters.get(\"num_batches\", 10)\n",
        "            self.batch_size = parameters.get(\"batch_size\", 1000)\n",
        "            self.test = parameters.get(\"test_mode\", False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ce7wlxycY76k",
        "colab": {}
      },
      "source": [
        "pmf = PMFRecSys()\n",
        "pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 15, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':False})\n",
        "# When maxepoch is over 15, the test accuracy will remain the same while the train accuracy will continue increasing, which will cause the overfiting problem worse."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p56cFny7Y_Z_",
        "outputId": "f151dedd-1b29-4329-9e0e-95d9032cfe37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "pmf.predict_all(rating_df, num_users, num_items)\n",
        "pmf.plot_error()"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3xV9f3H8dcnOyGQQIBAEmQbDLIM\n4gAU6gCtAxG1/NyjSlvbulBpratWUbTWVWcBsSqioNIWxQE42QKy90qYAmEmZH1+f5wTvISbQZKb\ne0/yeT4e95F7z7jnfW+S+7nfM75fUVWMMcaY0sKCHcAYY0xosgJhjDHGLysQxhhj/LICYYwxxi8r\nEMYYY/yyAmGMMcYvKxAeIiIPi8i/g52jskTkgIi0C3YOExwislRE+gU7h6k6KxAhxP1ALbkVi0iu\nz+Ora3hbY0VEReTSUtOfdaffUN1tqGq8qq6rRJZ+IpJV3e1VlYjcICJFPu/1ehEZIyInHsdzjBWR\nxwKZs7LbcX9/HQKdpSKq2llVZwTiuUWkpYj8S0S2ish+EVkhIo+ISINAbK++sgIRQtwP1HhVjQc2\nARf7THs7AJtcBVxX8kBEIoArgbUB2Faom+m+7wnAuUAuMF9ETg5urNDk/q0Ea9tNgJlALHCGqjYE\nzgMSgfZVeL6gvZZQZwXCe6JEZJz7rWmpiPQsmSEiKSIyUUR2ut+C/1DBc/0H6CMijd3HA4EfgW0+\nzxkmIg+IyEYR2eFuO8Gd94mI3O77hCKySEQGu/ePfJMVkWgReVpENonIdhF5RURiK3qx5a1X0vIQ\nkbvdbFtF5EafdS8UkWXue5UtIvdUtD1VLVLVtar6W+Ar4GGf53tfRLaJyF4R+VpEOrvTbwWuBu51\nWyD/caffLyJr3e0vE5HLfJ6rg4h85T7XTyLyns+8TiLyuYjsFpGVInJleds5HiJyk4gsF5E9IjJV\nRFr7zHtORDaLyD4RmS8ifX3mPSwiH4jIv0VkH3CDO21COX+PG0TkXJ/1y1v2FBFZ4M57X0TeK6el\ndBewH7hGVTcAqOpmVf2jqv4oIm3cv70In+efISK3uPdvEJHvxGkt7wL+KiI5vl8GRKSZOC345u7j\ni0Rkobvc9yLS9Xjfey+yAuE9lwDjcb4tTQZeBOeDHOcDfxGQCpwD3CEiA8p5rjzgY+BX7uPrgHGl\nlrnBvfUH2gHxJdsE3gWGliwoIhlAa+B/frY1EjgR6A50cDM+WP5LrdR6LXC+9acCNwMv+RS8fwG3\nud8wTwamVWJ7viYBfX0efwJ0BJoDPwBvA6jqa+79p9zW3sXu8mvd9ROAR4B/i0hLd95fgc+AxkAa\n8AKAOLtIPgfecbfzK+CfIpJRznYqRZzdiX8CBgPNgG9wfocl5uK8z03c7b8vIjE+8y8FPsD52ytp\n0fr9eyxDWX+7UcCHwFh32+8Cl/l/CsBp4U1S1eLyXm8FTgPWAcnAozi/66E+868EvlLVHSLSAxgN\n3AYkAa8Ck0Ukuhrb9wZVtVsI3oANwLmlpj0MfOHzOAPIde+fBmwqtfwIYEwZzz8WeAzog9NcTwS2\n4zTbvwVucJf7Evitz3rpQAEQATQEDgKt3Xl/A0b7LKs4H+riLtfeZ94ZwHr3fj8gy0/GyqyXC0T4\nzN8BnO7e34TzT92ogvf6BuBbP9MHAgVlrJPovr4E3/ezgu0sBC51748DXgPSSi1zFfBNqWmvAg8d\nx3YU6OBn+ifAzT6Pw4BDJb8/P8vvAbr5/O19Xdm/x9J/w+UtC5wFZAPiM//bsl4nsBoYVs7rb+O+\nB75/FzOAW3x+36X/V84F1vo8/g64zr3/MvDXUsuvBM4u7/dQF27WgvCebT73DwExblO6NZDiNoFz\nRCQH59ticnlPpqrf4nyb/DPwX1XNLbVICrDR5/FGnOKQrKr7cVoLJS2Qofz8zdJXMyAOZ59+SbZP\n3enlqcx6u1S10OfxIZxWDsDlwIXARnd3zhkVbK+0VGA3gIiEi8hId5fRPpwPP4CmZa0sItf57JbI\nwWnFlCx/L04BnOPubrnJnd4aOK3U7/FqnJZSdbUGnvN53t1uhlQ37z3u7qe97vyEUq9vs5/nLOvv\n0Z+ylk0BstX95C1nWyV2AS3LmV8ZpZ9/OhAnIqeJSBucltSH7rzWwN2lfiet3Nx1mh2cqTs243yz\n7liFdf+Ns9umv595W3D+QUqcABTitDbA2R3wkIh8DcTg/KOV9hPON/3Oqpp9HLmquh4AqjoXuFRE\nIoHbgQk4/9iVdRnObhiA/8PZxXIuTnFIwPmGLSWb813R3bf/Os6uvpmqWiQiC0uWV9VtwK/dZfsA\nX7jv4WacXRvnlfWyjiN/aZuBv6mfEx7c4w33unmXqmqxiPi+vupuuzxbgVQREZ8i0YqyT5b4ArhM\nRB5R/7uZDro/44B97v3SBfao1+L+fibgfMnZjvNlab87u+R9+1ulX1EdYS2IumMOsF9E7hORWPcb\n78kicmol1n0e5yyQr/3Mexe4U0Taikg88Djwns+39ik4BeRRd/ox/7DutNeBZ30O+qWWPj4iIjG+\nN5x/4grX80dEokTkahFJUNUCnA+KCvdZu+9bWxF5AWcX1iPurIbAYZxvr3Hu++BrO84xmhIN3Pw7\n3ee9EacFUbKdK0QkzX24x122GPgvcKKIXCsike7tVBE5qYztlCWq1PsZDrwCjJCfD64niMgVPq+v\n0M0bISIPAo0qsZ2aMBMoAm4XkQj3WEmvcpb/O062N91CXPJ38XcR6aqqO3F2WV3j/j5vonJnN72D\ns4vvavd+ideBYW7rQkSkgYj8UkQaHvcr9RgrEHWEqhYBF+E0jdfjfPt+A+ebbkXr7lbVL0s18UuM\nBt7CKR7rcQ5s/95n3cM4B/jO5eh/qtLuA9YAs9xdNF/gHM8okYrTWvC9ta/EeuW5FtjgrjcM5x+/\nLGeIyAGcQjID5wPoVFVd7M4fh7N7LRtYBswqtf6/gAx3F8RHqroMeAbnw2870AVnv3aJU4HZ7jYn\nA39U1XXut9bzcXbbbcHZLfMkEO1vO+W8nqUc/V7eqKofus813n1PlgAXuMtPxdl9t8p9nXmUv5un\nxqhqPs6B85uBHOAanEJ5uIzldwNn4hwLmy0i+3GOle3F+VsBp3U2HKegdwa+r0SO2TitjxSc4zUl\n0+e5z/ciTjFfg3Mco84T/58JxhgTPCIyG3hFVccEO0t9Zi0IY0zQicjZItLC3cV0PdAVp0VjgsgO\nUhtjQkE6zkkEDXCuTxiiqluDG8nYLiZjjDF+2S4mY4wxftWZXUxNmzbVNm3aVHn9gwcP0qCBNzqC\n9FJW8FZeL2UFb+X1UlbwVt7qZJ0/f/5Pqur/otVgX8pdU7fMzEytjunTp1dr/drkpayq3srrpayq\n3srrpayq3spbnazAPLWuNowxxhwPKxDGGGP8sgJhjDHGrzpzkNoYE3wFBQVkZWWRl5d3zLyEhASW\nL18ehFRV46W8lckaExNDWloakZGRlX5eKxDGmBqTlZVFw4YNadOmDSJy1Lz9+/fTsKF3+rfzUt6K\nsqoqu3btIisri7Zt21b6eev9LqaPFmTTe+Q0bvj0IL1HTuOjBcfdq7QxxpWXl0dSUtIxxcEEl4iQ\nlJTkt2VXnnrdgvhoQTYjJi0mt6AIgOycXEZMcjrvHNQjNZjRjPEsKw6hqSq/l3pdIEZNXXmkOJTI\nLSjisf8to3NKIxLjokiMiyQy/PgaWh8tyGbU1JVsycklJTGW4QPSreAYYzynXheILTmlR9d0/HQg\nn/Oe/XnsnPjoCBJiI2ncIJLEWKdoJMZF0jguypkeVzItinkbd/Ps56vIK3DGprFWiTG1Z9euXZxz\nzjkAbNu2jfDwcJo1cy4SnjNnDlFRURU+x4033sj9999PSkrZI4q+9NJLJCYmcvXV5Q0xUjl9+vRh\n586dREdHk5+fz3nnncdjjz1GQkLZQ7kUFxfz1FNPcf/991d7++Wp1wUiJTGWbD9FIqlBFA9d0pmc\nQ/nkHCpgz6F89ro/c3ILyM7JJedQPntzCyiuRF+HuQVF/OWjJRQUFdOmaQNaJ8XRLD7amuKm3qvp\n1nZSUhILFy4E4OGHHyY+Pp577rnnqGWOXCUc5n/PwJgxzhAU+/fv9zsf4He/+12VM/rz3nvv0b17\nd/Lz87n33nsZPHgwX375ZZnLFxcXM3LkSCsQgTR8QPpRxyAAYiPD+ctFGVzSreLxyIuLlf15hUcK\nx55D+dw4Zq7fZfcfLmT4Bz8eeRwXFU7rpAa0bhJH66ZxtElyCkebpAa0aBRDWNixxaPknyk7J5fU\nWdNs15XxtNo8BrhmzRouueQSevTowYIFC/j888955JFH+OGHH8jNzeWqq67iwQcfBJxv9C+++CKt\nW7cmMTGRYcOG8cknnxAXF8fHH39M8+bNeeCBB2jatCl33HEHffr0oU+fPkybNo29e/cyZswYzjzz\nTA4ePMh1113H8uXLycjIYMOGDbzxxht07969zJxRUVE8/fTTtGvXjqVLl9K5c2cuvvhitmzZQl5e\nHnfeeSe33HIL999/P/v376d79+507dqVl156ye9y1VWvC0TJH+GRD93j/AYTFiYkxEWSEPfzecWp\nZbRKUhJiePvXp7Nh10E27TrEhl0H2bjrEKt27OfLFdspKPq5KRIVEcYJTeJokxRH66QGtEmKIzsn\nlzHfbeBwoe26Mt7wyH+WsmzLviOPi4qKCA8PP/J4waYc8ouOHiY8t6CIez/4kXfnbPL7nBkpjXjo\n4s5VyrNixQrGjRtHz549ARg5ciRNmjShsLCQ/v37M2TIEDIyMo5aZ+/evZx99tmMHDmSu+66i9Gj\nR/v91q6qzJkzh8mTJ/Poo4/y6aef8sILL9CiRQsmTpzIokWLOOWUUyqVMyIigq5du7JixQo6d+7M\nm2++SZMmTTh06BA9e/bk8ssvZ+TIkbzxxhtHWkv79+/3u1zjxo2r9F4dyVKtteuAQT1SGdQjlRkz\nZtCvX79qP19ZrZJ7B3aibdMGtG16bI+LRcXK1r25bPQpHBt+Osim3Yf4ds1PR45nlJZbUMSoqSut\nQBhPKl0cKppeXe3btz9SHADeffdd/vWvf1FYWMiWLVtYtmzZMQUiNjaWCy5whu3OzMzkm2++8fvc\ngwcPPrLMhg0bAPj222+57777AOjWrRudO1e+sKnPOD3PPvsskydPBpzrTNauXeu3FeJvOd/XWxX1\nvkDUNN9WSWX3q4aHCWmN40hrHEfvDk2Pmqeq7Nh/mNMf/xJ/hzuyc3L5Ytl2zk5vdtxnWxkTSKW/\n6Ze+mKv3yGl+W9upibG8d9sZNZ7Htzvs1atX89xzzzFnzhwSExO55ppr/F4j4HtQOzw8nMLCQr/P\nHR0dXeEylVVYWMiSJUs46aST+OKLL/j666+ZNWsWsbGx9OnTx2/O6dOnV2q542UFIgBKWiU1QURI\nbhRT5gH1MIFbxs2jaXw0g09J5YrMNDome+PqT1O/ldXaHj4gPeDb3rdvHw0bNqRRo0Zs3bqVqVOn\nMnDgwBrdRu/evZkwYQJ9+/Zl8eLFLFu2rMJ18vPzGTFiBB06dCAjI4Ply5fTpEkTYmNjWbp0KXPn\nOsc4IyKcj+7CwkIiIiLYt2+f3+WqywqER5T1z/TYoM40io3i/XmbGf3tel77eh3dWiVyRWYaF3dL\nISG28v2uGFObqtLarimnnHIKGRkZdOrUidatW9O7d+8a38bvf/97rrvuOjIyMo7cyjp19aqrriI6\nOprDhw9z/vnnM2nSJAB++ctf8tprr5GRkUF6ejqnnXbakXVuvvlmunbtSs+ePXnmmWd46623/C5X\nHXVmTOqePXvqvHnzqrx+TR2DCKSjzmLy88/004HDfLQgmw/mZ7Fi236iI8IY0LkFQzLT6N2hKeF+\nzoyqDV54b0t4KSuEXt7ly5dz0kkn+Z3npb6NoPp5CwsLKSwsJCYmhtWrV3P++eezevXqI9/+a1Jl\ns/r7/YjIfFX1e7DCWhAeUtEB9abx0dzStx0392nLkux9vD9/Mx8v3MLkRVtISYjh8sw0hmSm0TrJ\nG8MoGuNlBw4c4JxzzqGwsBBV5dVXXw1IcQgkb6U1lSIidElLoEtaAn+68CS+WL6d9+dl8dL0Nbww\nbQ292jbhisw0LuzSkgbREdY1iDEBkJiYyPz584Mdo1qsQNRxMZHhXNQ1hYu6prBtbx4Tf8jig/lZ\nDP/gRx6avJSTUxqxMGsv+XZ9hakhqmq9BISgqhxOsPMi65EWCTH8rn8Hpt19Nh8MO4OLu6Ywd8Oe\nI8WhRMn1FcYcr5iYGHbt2lWlDyMTOCXjQcTExBzXetaCqIdEhJ5tmtCzTRMmzNvsd5myOjI0pjxp\naWlkZWWxc+fOY+bl5eUd9wdUMHkpb2WylowodzysQNRzZV1fkZIYG4Q0xusiIyPLHLFsxowZ9OjR\no5YTVZ2X8gYqa8B2MYnIaBHZISJLypjfSURmishhEbmn1LyBIrJSRNaISGC7K6znhg9IJzYy/Jjp\nnVo2tN0ExtRzgTwGMRYo79LE3cAfgKd9J4pIOPAScAGQAQwVkYxjVzc1YVCPVJ4Y3IXUxFgESEmM\n4cz2Tfhy+Q4e/HgpxZXpz9wYUycFbBeTqn4tIm3Kmb8D2CEivyw1qxewRlXXAYjIeOBSoOLr1E2V\nlO4aRFUZ+ckKXv16HQcPF/LUkK5EWD9PxtQ7Ab2S2i0Q/1XVk8tZ5mHggKo+7T4eAgxU1Vvcx9cC\np6nq7X7WvRW4FSA5OTlz/PjxVc564MAB4uPjq7x+baqNrKrKf9YVMGl1AZnJ4QzrFk1kFa/Etvc2\ncLyU10tZwVt5q5O1f//+dfNKalV9DXgNnK42qtPlQKh1WVCe2sravz+c/O16Hv3vMt7a0IBXr8kk\nNurY4xUVsfc2cLyU10tZwVt5A5U1FPcbZAOtfB6nudNMENzUpy1PXd6Vb1fv5LrRs9mXVxDsSMaY\nWhKKBWIu0FFE2opIFPArYHKQM9VrV57aiueH9mDBphyufn02uw/mBzuSMaYWBPI013eBmUC6iGSJ\nyM0iMkxEhrnzW4hIFnAX8IC7TCNVLQRuB6YCy4EJqro0UDlN5VzUNYXXr+vJqu37uerVmWzfV/3B\nSIwxoS2QZzENrWD+NpzdR/7mTQGmBCKXqbr+nZoz9sZe3PLmXK54ZSZv33IarZrEBTuWMSZAQnEX\nkwlhZ7RP4u1fn87e3AKueGUma3YcCHYkY0yAWIEwx617q0Teu+10CouVq16dyZLsvcGOZIwJACsQ\npko6tWjEhNtOJzoijKGvz2L+xt3BjmSMqWFWIEyVtWsWz/u/OZOkBlFc88Ycvl39U7AjGWNqkBUI\nUy2pibFMGHYGrZPiuGnsXD5bui3YkYwxNcQKhKm25g1jGH/r6ZyU0ojfvP0DHy+06xqNqQusQJga\nkRgXxdu3nMapbRpzx3sLeWf2pmBHMsZUk6f7YjKhJT46grE39uI3/57Pnz5czKx1PzF/Yw7ZObmk\nzprG8AHpNs61MR5iLQhTo2Iiw3n12p50T0tg8qKtR0ary87JZcSkxXy0wHY/GeMVViBMjYuKCGPH\ngcPHTM8tKGLU1JVBSGSMqQorECYgtub476tpi5/xr40xockKhAmIlMTY45pujAk9ViBMQAwfkE5s\n5NGDC0WECcMHpAcpkTHmeNlZTCYgSs5WGjV1Jdk5ucRFhXMov4gTkqz3V2O8wloQJmAG9Ujlu/t/\nwdiBDZj9p3NITYzlrvcWcii/MNjRjDGVYAXC1IqGMZE8c2U3Nu4+xN/+tzzYcYwxlWAFwtSa09sl\n8eu+7Xh79iamr9wR7DjGmApYgTC16q7zTiQ9uSH3fvCjjW1tTIizAmFqVUxkOM9e1Z2cQ/k88NFi\nVDXYkYwxZbACYWpdRkoj7jzvRKYs3sZH1vOrMSHLCoQJitvOak/P1o158OOlR/prMsaEFisQJijC\nw4S/X9md4mLlngmLKC62XU3GhBorECZoTkiK4y8XZTBz3S7GfL8h2HGMMaVYgTBBddWprTj3pOY8\n+ekKVm/fH+w4xhgfViBMUIkITwzuSnx0BHe8t5D8wuJgRzLGuKxAmKBr1jCaxy/rwtIt+3j+y9XB\njmOMcVmBMCFh4MktGJKZxj9nrGH+xj3BjmOMIYAFQkRGi8gOEVlSxnwRkedFZI2I/Cgip/jMKxKR\nhe5tcqAymtDy0MUZtEyI5e4JCzl42Dr0MybYAtmCGAsMLGf+BUBH93Yr8LLPvFxV7e7eLglcRBNK\njurQb4p16GdMsAWsQKjq18Ducha5FBinjllAooi0DFQe4w0lHfq9M3sT01dYh37GBFMwj0GkApt9\nHme50wBiRGSeiMwSkUG1H80E05EO/SZah37GBJMEsrM0EWkD/FdVT/Yz77/ASFX91n38JXCfqs4T\nkVRVzRaRdsA04BxVXevnOW7F2T1FcnJy5vjx46uc9cCBA8THx1d5/drkpaxQtbyb9hXxyMw8ejQP\n53fdoxGRAKU7Wn14b4PFS1nBW3mrk7V///7zVbWn35mqGrAb0AZYUsa8V4GhPo9XAi39LDcWGFLR\ntjIzM7U6pk+fXq31a5OXsqpWPe9L01dr6/v+qxPnb67ZQOWoL+9tMHgpq6q38lYnKzBPy/hcDeYu\npsnAde7ZTKcDe1V1q4g0FpFoABFpCvQGlgUxpwmSkg79HrIO/YwJikCe5vouMBNIF5EsEblZRIaJ\nyDB3kSnAOmAN8DrwW3f6ScA8EVkETMfZDWUFoh460qGfWod+xgRDRKCeWFWHVjBfgd/5mf490CVQ\nuYy3lHTod/+kxYz+bj239G0X7EjG1Bt2JbUJeSUd+j01dSWrrEM/Y2qNFQgT8nw79LvTOvQzptYE\nbBeTMTWpWcNonhjchdvems8pf/2cg4cLSUmMZfiAdAb1SK34CYwxx80KhPGM3PwiwkU44PbTlJ2T\ny4hJiwGsSBgTALaLyXjGqKkrKSp1YWduQRGjpq4MUiJj6jYrEMYztpRxLURZ040x1WMFwnhGSmLs\ncU03xlSPFQjjGcMHpBMbGX7M9Fv6tg1CGmPqPisQxjMG9UjlicFdSE2MRYDkRtFEhgtTl26jyK6y\nNqbG2VlMxlMG9Ug96oylCXM3c+/EH3nt63X8pl/7ICYzpu6xFoTxtCt6pnFhlxY889lKFmftDXYc\nY+oUKxDG00SExy/rQrOG0fxx/AIO5dtY1sbUFCsQxvMS46J45spurN91kL/+1zr+NaamWIEwdcKZ\n7Zty21nteXfOZj5dsi3YcYypE6xAmDrjrvNOpEtqAvdP+pFte/OCHccYz7MCYeqMqIgw/vGr7hwu\nKObu9xfaAEPGVJMVCFOntG8Wz0MXZ/Ddml288e26YMcxxtOsQJg656pTWzGgczKjpq5kSbad+mpM\nVVmBMHWOiDBycFeaNIjiD+MXkJtfFOxIxniSFQhTJzVuEMXfr+zO+p8O8tf/2amvxlSFFQhTZ/Xu\n0JRb+7bjndmb+GypnfpqzPGyAmHqtLvPT+fk1EbcN/FHtu+zU1+NOR5WIEydFhURxj+u6kFuQRH3\nvL/ITn015jhYgTB1Xofm8Tx4UWe+Wf0To79bH+w4xniGFQhTLwzt1YrzMpJ56tOVLN1ip74aUxlW\nIEy9ICI8eXlXEuMi+eP4hXbqqzGVYAXC1BtNGji9vq7ZcYDHpywPdhxjQp4VCFOv9O3YjF/3bctb\nszbyxbLtwY5jTEgrt0CIyC987rctNW9wBeuOFpEdIrKkjPkiIs+LyBoR+VFETvGZd72IrHZv11fu\npRhTOfcMSCejZSPunfgjO/bbqa/GlKWiFsTTPvcnlpr3QAXrjgUGljP/AqCje7sVeBlARJoADwGn\nAb2Ah0SkcQXbMqbSoiPCeX5odw4eLuSe93+0U1+NKUNFBULKuO/v8VFU9WtgdzmLXAqMU8csIFFE\nWgIDgM9Vdbeq7gE+p/xCY8xx69C8IQ9clMHXq3Yy9vsNwY5jTEiKqGC+lnHf3+PjlQps9nmc5U4r\na/oxRORWnNYHycnJzJgxo8phDhw4UK31a5OXskLo5k1TpUfzcB7/3zIi96ynVcOwkM1aFi/l9VJW\n8FbeQGWtqEC0E5HJOK2Fkvu4j9uWvVrtUNXXgNcAevbsqf369avyc82YMYPqrF+bvJQVQjtv11MP\nM/C5b3hrTTiTb+/DrO++Cdms/oTye1ual7KCt/IGKmtFBeJSn/tPl5pX+vHxygZa+TxOc6dlA/1K\nTZ9RzW0Z41dSfDTPXNGN60bPIfOvn3Mwv4jUWdMYPiCdQT38NlyNqTfKLRCq+pXvYxGJBE4GslV1\nRzW3PRm4XUTG4xyQ3quqW0VkKvC4z4Hp84ER1dyWMWXafTCf8DDhoHvxXHZOLiMmLQawImHqtYpO\nc31FRDq79xOARcA4YIGIDK1g3XeBmUC6iGSJyM0iMkxEhrmLTAHWAWuA14HfAqjqbuCvwFz39qg7\nzZiAGDV1JUWlzmTKLShi1NSVQUpkTGioaBdTX1Ut+UC/EVilqoNEpAXwCfBuWSuqarkFRFUV+F0Z\n80YDoyvIZkyN2JKTe1zTjakvKjrNNd/n/nnARwCqaqOvmDojJTHW7/SWCTG1nMSY0FJRgcgRkYtE\npAfQG/gUQEQiAP//VcZ4zPAB6cRGhh8zPSUxBqeha0z9VFGBuA24HRgD3OHTcjgH+F8ggxlTWwb1\nSOWJwV1IdVsSqYmxDOyczLyNObw4bU2Q0xkTPBWdxbQKP1cxq+pUYGqgQhlT2wb1SGVQj9Qj55Or\nKndNWMQzn6/ihKQ4Lu1uZzOZ+qfcAiEiz5c3X1X/ULNxjAkNIsLIy7uQvSeX4R/8SFrjWDJbNwl2\nLGNqVUW7mIYBfYAtwDxgfqmbMXVWdEQ4r16bSUpCDL8eN5+Nuw4GO5IxtaqiAtESpyuLAcC1QCTw\nsaq+qapvBjqcMcHWuEEUY27sRbEqN46dy95DBcGOZEytKbdAqOouVX1FVfvjXAeRCCwTkWtrJZ0x\nIaBt0wa8ek0mm3cfYti/55NfWBzsSMbUikqNKOcO5vNH4BqcC+Rs95KpV05rl8RTQ7oyc90u/vzh\nYjv91dQLFR2kfhT4JbAcGDInbrQAABoZSURBVA+MUNXC2ghmTKi5rEca6386xPNfrqZN0wb8rn+H\nYEcyJqAq6mrjAWA90M29PS4i4HT3raraNbDxjAktd57bkY27DjJq6kpOaBLHxd1Sgh3JmICpqEAE\nfcwHY0KJiPDk5V3J3pPL3e8vIiUxlszWNiKuqZsqOki90d8NZ8S3PrUT0ZjQEhMZzmvX9aRlQgy3\njpvHpl2Hgh3JmICoqLvvRiIyQkReFJHzxfF7nG66r6ydiMaEniYNohh9w6kUFis3jp3D3lw7/dXU\nPRWdxfQWkA4sBm4BpgNDgEGqeml5KxpT17VvFs8r12Syafchfvv2fAqK7PRXU7dUVCDaqeoNqvoq\nMBTIAAao6sLARzMm9J3RPoknBnfluzW7eODDJXb6q6lTKjpIfaTdrKpFIpKlqnkBzmSMpwzJTGPj\nroO8MG0NbZo24Df92gc7kjE1oqIC0U1E9rn3BYh1H5ec5toooOmM8Yi7zjuRDbsO8eSnK2idFMeF\nXVoGO5Ix1VZRd9/HjqJijDmGiDBqSFe25ORy53sLaZkQQ48T7PRX422V6mrDGFOxmMhwXrs2k+RG\nMfx63Dw277bTX423WYEwpgYlxUcz+oZTyS8s5qaxc+30V+NpFR2DMMYcpw7NndNfrxs9hyte/p4D\n+YVszckjJTGW4QPSGdTDRqcz3mAtCGMC4MwOTRnSM41VOw6wJScPBbJzchkxaTEfLcgOdjxjKsUK\nhDEB8s2qn46ZlltQxKipK4OQxpjjZwXCmADZkpN7XNONCTVWIIwJkJTEWL/TWybE1HISY6rGCoQx\nATJ8QDqxkcdeShQZLuw5mB+ERMYcHysQxgTIoB6pPDG4C6mJsQiQmhjLjb1bs3XfYS5/5Xu7TsKE\nvICe5ioiA4HngHDgDVUdWWp+a2A00AzYDVyjqlnuvCKcXmQBNqnqJYHMakwgDOqResxprRd2SeHm\nsXMZ/PL3jLnhVE5OTQhSOmPKF7AWhIiEAy8BF+D0AjtURDJKLfY0MM4duvRR4Amfebmq2t29WXEw\ndcapbZow8TdnEhkmXPXqTL5ZvTPYkYzxK5C7mHoBa1R1narmA+OB0mNIZADT3PvT/cw3pk7qmNyQ\nSb/tTasmcdw4Zi6TfsgKdiRjjiGB6r9eRIYAA1X1FvfxtcBpqnq7zzLvALNV9TkRGQxMBJqq6i4R\nKQQWAoXASFX9yM82bgVuBUhOTs4cP358lfMeOHCA+Pj4Kq9fm7yUFbyVt7azHipQXliQx/LdxVxx\nYiQXto1ERCq9vr23geOlvNXJ2r9///mq2tPvTFUNyA1n5Lk3fB5fC7xYapkUYBKwAOdYRRaQ6M5L\ndX+2AzYA7cvbXmZmplbH9OnTq7V+bfJSVlVv5Q1G1ryCQr39nR+09X3/1Qc/WqyFRcWVXtfe28Dx\nUt7qZAXmaRmfq4E8SJ0NtPJ5nOZOO0JVtwCDAUQkHrhcVXPcednuz3UiMgPoAawNYF5jgiI6Ipzn\nrupOi0bRvP7NerbvO8w/ftWdGD+nyBpTmwJ5DGIu0FFE2opIFPArYLLvAiLSVERKMozAOaMJEWks\nItElywC9gWUBzGpMUIWFCX/+ZQYP/PIkPl26jWv/NZucQ3athAmugBUIVS0EbgemAsuBCaq6VEQe\nFZGSs5L6AStFZBWQDPzNnX4SME9EFuEcvB6pqlYgTJ13S992vDC0B4s272XIKzPJtm45TBAF9DoI\nVZ0CTCk17UGf+x8AH/hZ73ugSyCzGROqLu6WQtP4aG59ax6D//kdY2/sxUktbXRfU/vsSmpjQtAZ\n7ZN4f9gZCMKVr8zk+zXH9gxrTKBZgTAmRHVq0YhJvz2TlokxXD9mDpMXbQl2JFPPWIEwJoSlJMby\n/m1n0uOExvzh3QW8/vW6YEcy9YgNOWpMiEuIi2TcTb24a8JC/jZlOVv35tElpRFPf76K7JxcUmdN\ns6FMTUBYgTDGA2Iiw3lx6Ck82nAZo79bT7hAkdsJQslQpoAVCVOjbBeTMR4RFiY8dHEGjWIijhSH\nEjaUqQkEKxDGeIiIsD+v0O88G8rU1DQrEMZ4TFlDmbawoUxNDbMCYYzHlDWUaW5+Ed+vteslTM2x\nAmGMx/gOZQrOUKZ/PKcjjRtE8X+vz+aR/ywlr6AoyClNXWBnMRnjQSVDmc6YMYN+/foBcNvZ7Xjy\nkxWM+W4DX63ayd+v7E73VonBDWo8zVoQxtQRcVERPHLpyfz75tPIyy/i8pe/55nPVpJfWBzsaMaj\nrEAYU8f06diUT+88i0HdU3lh2hou++d3rNy2P9ixjAdZgTCmDmoUE8kzV3bj1Wsz2b4vj4tf+JZX\nvlpLUXFghhg2dZMVCGPqsAGdWzD1jrP4RafmjPxkBVe9OpMNPx0MdizjEVYgjKnjkuKjefmaU3j2\nqm6s3L6fC577hrdmbSwZF96YMlmBMKYeEBEu65HGZ3eeRc82jfnLR0u4bvQctu61q69N2axAGFOP\ntEyIZdxNvXhs0MnM27CH85/9mg8XZFlrwvhl10EYU8+ICNec3pq+HZty94RF3PneIqYu2U6fjkm8\nPGMdW3JySUmMtS7EjRUIY+qr1kkNeO+2M3jjm3U89ekKPl267cg860LcgO1iMqZeCw8Tbju7PUnx\n0cfMsy7EjRUIYww79x/2O926EK/frEAYY8rsQlwExs3cQEGRdddRH1mBMMb47UI8OiKMtk0b8ODH\nSznv718xZfFWO9upnrECYYw5qgtxwelC/MnLu/LFXWcz5oZTiYoI47dv/8Bl//ye2et2BTuuqSV2\nFpMxBvi5C/HS+ndqzlknNmPiD1n8/bNVXPXaLM49qTn3DexEx+SGQUhqaou1IIwxFQoPE67s2Yrp\n9/Tj3oHpzF63mwH/+Jr7J/7I9n15wY5nAiSgBUJEBorIShFZIyL3+5nfWkS+FJEfRWSGiKT5zLte\nRFa7t+sDmdMYUzmxUeH8tl8Hvrq3Pzec2ZaJP2Rx9qjpjJq6gn15BcGOZ2pYwAqEiIQDLwEXABnA\nUBHJKLXY08A4Ve0KPAo84a7bBHgIOA3oBTwkIo0DldUYc3yaNIjiwYsz+PKufpyf0YKXpq+l36gZ\njPluvQ1QVIcEsgXRC1ijqutUNR8YD1xaapkMYJp7f7rP/AHA56q6W1X3AJ8DAwOY1RhTBSckxfH8\n0B785/Y+dGrRkEf+s4xz//4V/1m0xc54qgMkUL9EERkCDFTVW9zH1wKnqertPsu8A8xW1edEZDAw\nEWgK3AjEqOpj7nJ/AXJV9elS27gVuBUgOTk5c/z48VXOe+DAAeLj46u8fm3yUlbwVl4vZYXQyquq\nLP6piAkr88k6oLRNCOPKE6PYc7iYiasK2JVXTFJMGJefGMmZKZHBjluhUHpvK1KdrP3795+vqj39\nzQv2WUz3AC+KyA3A10A2UFTZlVX1NeA1gJ49e2rJ4O1V4Tv4e6jzUlbwVl4vZYXQy9sf+F2x8uGC\nbJ75bCVPzs0jTMAZyE7Ylae8tbyIjJMyQr6Pp1B7b8sTqKyB3MWUDbTyeZzmTjtCVbeo6mBV7QH8\n2Z2WU5l1jTGhKTxMGJKZxvR7+tEoJoLSo5xaH0/eEcgCMRfoKCJtRSQK+BUw2XcBEWkqIiUZRgCj\n3ftTgfNFpLF7cPp8d5oxxiNiIsPZn1fod152Tq6Nj+0BASsQqloI3I7zwb4cmKCqS0XkURG5xF2s\nH7BSRFYBycDf3HV3A3/FKTJzgUfdacYYDymrjyeAXzzjnPV04LD/ImKCL6DHIFR1CjCl1LQHfe5/\nAHxQxrqj+blFYYzxoOED0hkxaTG5BT8fWoyJDOOqnq1YnL2XR/6zzLk6+9RWXH9mG1o1iQtiWlNa\nsA9SG2PqsJID0aOmriQ7J5fUUiPVLdi0h9HfbWDM9xsY/d16BnRuwU192tKzdWNEJJjRDVYgjDEB\nVtLHk78zbXqc0JgXTmjMny7sxLiZG3ln9iY+WbKNrmkJ3NS7LRd2aUlUhPUIFCz2zhtjgq5lQiz3\nDezEzBG/4LFBJ3PgcCF3vLeQvk9N46Xpa9hzMD/YEesla0EYY0JGXFQE15zemv/rdQJfrd7J6G/X\nM2rqSl6YtprLeqRxc582dGhuPcjWFisQxpiQExYm9E9vTv/05qzctp8x361n4g9ZvDtnE2ed2Iyb\n+7Rl94HDPP3ZKrbk5JJS6tiGqRlWIIwxIS29RUNGXt6V4QPSeWf2JsbN2sj1o+cgQMmVFNk5uYyY\ntBjAikQNsmMQxhhPSIqP5vfndOS7+35B47hISl9m51yhvSIo2eoqKxDGGE+Jiggj55D/sSeyc/J4\necZaG8SohliBMMZ4TllXaEeFh/Hkpys444kvuXHMHD5ZvNXGp6gGOwZhjPEcf1dox0aG88TgLnRN\nS+CD+VlM/CGL37z9A43jIrm0eypX9Eyjc0pCEFN7jxUIY4zn+F6h7e8spnsHduLu89P5ZvVO3p+X\nxTuzNzH2+w10TmnEFZlpXNo9lcYNooL5EjzBCoQxxpNKrtAuS3iY0C+9Of3Sm7PnYD6TF23h/fmb\nefg/y3h8ygrOy0hmSM80zurYjPAw69bDHysQxpg6r3GDKK4/sw3Xn9mGZVv28f78zXy0IJv/Ld5K\ncqNoBp+SxhWZabRrFs9HC7J/7jtq1rR6fX2FFQhjTL2SkdKIh1I6M+KCk/hy+Xben5/Fq1+t5eUZ\na2mbFEdWTi4FRc5JtPX9+gorEMaYeikqIowLurTkgi4t2bEvj0kLsnl66koKSw1kVDICXn0sEHaa\nqzGm3mveKIZhZ7cvc5S77Jxc3p69kR3769f1FdaCMMYYV0piLNk5ucdMDw8T/vzhEh74aAmnnNCY\nAZ2TGdC5Ba2TGgQhZe2xFoQxxriGD0gnNjL8qGmxkeE8PaQrn97RlzvOOZHc/CIen7KCs0fNYOA/\nvubZz1exbMs+VOveGNvWgjDGGFdFI+B1atGIP57bkc27DzF16TamLt3G89NW89yXqzmhSRznZyQz\n4OQWnHJC4zpx6qwVCGOM8VHeCHglWjWJ45a+7bilbzt27j/MF8u3M3XpNt6cuYE3vl1P0/hozstI\nZkDnZM5s35Qpi7eWeVFfKLMCYYwx1dCsYTRDe53A0F4nsD+vgOkrdzJ1yTY+XpjNu3M2ER0uFBZD\nkXrv1FkrEMYYU0MaxkRySbcULumWQl5BEd+t+Ynfv7uAw0VFRy2XW1DE41OWc2n3FERCd1eUFQhj\njAmAmMhwzjkpmdz8Ir/zd+w/TN+nptMvvRn9TmzOmR2SiIsKrY/k0EpjjDF1TFmnzibERtKpRSMm\n/ZDNv2dtIio8jF5tmzgFI7057Zs1CHrrwgqEMcYEUFldkz9ySWcG9UjlcGERc9fvYcbKHcxYtZPH\n/recx/63nLTGsUFvXViBMMaYAKqoa/LoiHD6dGxKn45NeQDI2nOIGSt3MmPlzjJaF81o3yweEQl4\nx4JWIIwxJsAq6prcV1rjOK45vTXXnN6aw4VFzNvgti5WHt26OKFJLPM25JBf5IyYF4izo6xAGGNM\niIqOCKd3h6b07tCUP//SaV18tcppXXyxbDulr92u6Y4FA9rVhogMFJGVIrJGRO73M/8EEZkuIgtE\n5EcRudCd3kZEckVkoXt7JZA5jTHGC9Iax3H1aa15/bqeZS6zxc8B8aoKWAtCRMKBl4DzgCxgrohM\nVtVlPos9AExQ1ZdFJAOYArRx561V1e6BymeMMV5W1tlRKYmxNbaNQLYgegFrVHWdquYD44FLSy2j\nQCP3fgKwJYB5jDGmziirY8HhA9JrbBsSqB4IRWQIMFBVb3EfXwucpqq3+yzTEvgMaAw0AM5V1fki\n0gZYCqwC9gEPqOo3frZxK3ArQHJycub48eOrnPfAgQPEx8dXef3a5KWs4K28XsoK3srrpazgjbzf\nbylg4qoCduUVkxQTxuUnRnJmSuRxPUf//v3nq6r/fVaqGpAbMAR4w+fxtcCLpZa5C7jbvX8GsAyn\nVRMNJLnTM4HNQKPytpeZmanVMX369GqtX5u8lFXVW3m9lFXVW3m9lFXVW3mrkxWYp2V8rgZyF1M2\n0MrncZo7zdfNwAQAVZ0JxABNVfWwqu5yp88H1gInBjCrMcaYUgJZIOYCHUWkrYhEAb8CJpdaZhNw\nDoCInIRTIHaKSDP3IDci0g7oCKwLYFZjjDGlBOwsJlUtFJHbgalAODBaVZeKyKM4TZrJwN3A6yJy\nJ84B6xtUVUXkLOBRESkAioFhqro7UFmNMcYcK6AXyqnqFJxTV32nPehzfxnQ2896E4GJgcxmjDGm\nfDYmtTHGGL8CdpprbRORncDGajxFU+CnGooTaF7KCt7K66Ws4K28XsoK3spbnaytVbWZvxl1pkBU\nl4jM07LOBQ4xXsoK3srrpazgrbxeygreyhuorLaLyRhjjF9WIIwxxvhlBeJnrwU7wHHwUlbwVl4v\nZQVv5fVSVvBW3oBktWMQxhhj/LIWhDHGGL+sQBhjjPGr3heIika9CyUi0sodgW+ZiCwVkT8GO1NF\nRCTcHTHwv8HOUhERSRSRD0RkhYgsF5Ezgp2pLCJyp/s3sERE3hWRmGBn8iUio0Vkh4gs8ZnWREQ+\nF5HV7s/GwcxYooyso9y/gx9F5EMRSQxmRl/+8vrMu1tEVESa1sS26nWB8Bn17gIgAxjqjmwXqgpx\nukfPAE4HfhfieQH+CCwPdohKeg74VFU7Ad0I0dwikgr8Aeipqifj9HX2q+CmOsZYYGCpafcDX6pq\nR+BL93EoGMuxWT8HTlbVrjjj0oyo7VDlGMuxeRGRVsD5OJ2g1oh6XSCo3Kh3IUNVt6rqD+79/Tgf\nYDUzOnkAiEga8EvgjWBnqYiIJABnAf8CUNV8Vc0JbqpyRQCxIhIBxBFiozGq6tdA6Q42LwXedO+/\nCQyq1VBl8JdVVT9T1UL34Syc4QpCQhnvLcCzwL04HZ/WiPpeIFJxBiMqkUUIf+D6ckfd6wHMDm6S\ncv0D5w+2ONhBKqEtsBMY4+4Se0NEGgQ7lD+qmg08jfNNcSuwV1U/C26qSklW1a3u/W1AcjDDHIeb\ngE+CHaI8InIpkK2qi2ryeet7gfAkEYnH6e32DlXdF+w8/ojIRcAOd8AnL4gATgFeVtUewEFCZxfI\nUdx995fiFLUUoIGIXBPcVMfHHcks5M+xF5E/4+zafTvYWcoiInHAn4AHK1r2eNX3AlGZUe9CiohE\n4hSHt1V1UrDzlKM3cImIbMDZdfcLEfl3cCOVKwvIUtWSFtkHOAUjFJ0LrFfVnapaAEwCzgxypsrY\n7o5DXzIe/Y4g5ymXiNwAXARcraF9wVh7nC8Li9z/tzTgBxFpUd0nru8FojKj3oUMERGcfeTLVfXv\nwc5THlUdoappqtoG532dpqoh+y1XVbcBm0Uk3Z10Ds4Y6aFoE3C6iMS5fxPnEKIH1EuZDFzv3r8e\n+DiIWcolIgNxdo9eoqqHgp2nPKq6WFWbq2ob9/8tCzjF/ZuulnpdINyDUCWj3i0HJqjq0uCmKldv\n4Fqcb+ML3duFwQ5Vh/weeFtEfgS6A48HOY9fbivnA+AHYDHO/3FIdQshIu8CM4F0EckSkZuBkcB5\nIrIapxU0MpgZS5SR9UWgIfC5+3/2SlBD+igjb2C2FdotJ2OMMcFSr1sQxhhjymYFwhhjjF9WIIwx\nxvhlBcIYY4xfViCMMcb4ZQXCeI7bW+UzPo/vEZGHa+i5x4rIkJp4rgq2c4XbY+z0UtPbiEiuz2nM\nC0Xkuhrcbj8v9KxrQkNEsAMYUwWHgcEi8oSq/hTsMCVEJMKng7eK3Az8WlW/9TNvrap2r8FoxlSJ\ntSCMFxXiXBh2Z+kZpVsAInLA/dlPRL4SkY9FZJ2IjBSRq0VkjogsFpH2Pk9zrojME5FVbp9SJeNa\njBKRue4YAbf5PO83IjIZP1dei8hQ9/mXiMiT7rQHgT7Av0RkVGVftIgcEJFnxRkH4ksRaeZO7y4i\ns3zGLmjsTu8gIl+IyCIR+cHnNcbLz+NevO1ejY37nixzn+fpyuYydZiq2s1unroBB4BGwAYgAbgH\neNidNxYY4rus+7MfkAO0BKJx+tx6xJ33R+AfPut/ivPlqSNOtwUxwK3AA+4y0cA8nP5v+uF07NfW\nT84UnG4xmuG01qcBg9x5M3DGcyi9ThsgF1joc+vrzlOcfoHA6ZjtRff+j8DZ7v1HfV7LbOAy934M\nTrfg/YC9OP31hOFckdsHSAJW8vPFs4nB/j3bLfg3a0EYT1KnF9txOAPnVNZcdcbUOAysBUq6yF6M\n88FcYoKqFqvqamAd0AlnIJbrRGQhzgdvEk4BAZijquv9bO9UYIY6neqV9Ah6ViVyrlXV7j63b9zp\nxcB77v1/A33ccSwSVfUrd/qbwFki0hBIVdUPAVQ1T3/uU2iOqmapajFOAWqDUzTycFo1g4GQ7n/I\n1A4rEMbL/oGzL9933IZC3L9rEQkDonzmHfa5X+zzuJijj8eV7n9GAQF+7/Oh3VZ/HoPhYLVeRdVV\ntZ8c3/ehCCg5dtILp4+ni3BaUaaeswJhPEtVdwMTcIpEiQ1Apnv/EiCyCk99hYiEufvs2+HsepkK\n/Mbtbh0RObESAwrNAc4WkabiDG87FPiqgnXKEwaUHF/5P+BbVd0L7BGRvu70a4Gv1BlxMEtEBrl5\no91xA/wSZ4yRBFWdgnNsp1s1cpo6ws5iMl73DE6PvCVeBz4WkUU434Kr8u1+E86HeyNgmKrmicgb\nOLtifnAP6u6kgiEzVXWriNwPTMdpgfxPVSvTxXV7d1dWidGq+jzOa+klIg/gjKVwlTv/euAVtwCs\nA250p18LvCoijwIFwBXlbLMhzvsW42a9qxI5TR1nvbka4xEickBV44Odw9QftovJGGOMX9aCMMYY\n45e1IIwxxvhlBcIYY4xfViCMMcb4ZQXCGGOMX1YgjDHG+PX/NupiT1ThnVAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-tkSLeDqzdu1"
      },
      "source": [
        "## Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "00OSiRl9zdu2"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YS4qfLOAzdu2",
        "outputId": "f50ed49f-614f-458d-a82d-afc2f631d384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "algorithm_instances_Q5 = [popularity_recsys,\n",
        "                          average_user_rating_recsys,\n",
        "                          item_cosine_recsys, \n",
        "                          user_cosine_recsys,\n",
        "                          pmf]\n",
        "cv_RMSE = CrossValidation('RMSE')\n",
        "cv_patk = CrossValidation('P@K')\n",
        "cv_ratk = CrossValidation('R@K')\n",
        "results_RMSE = cv_RMSE.run(algorithm_instances_Q5, num_users, num_items,k=5)\n",
        "results_patk = cv_patk.run(algorithm_instances_Q5, num_users, num_items,k=5)\n",
        "results_ratk = cv_ratk.run(algorithm_instances_Q5, num_users, num_items,k=5)"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2098.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2099.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2109.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2054.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2085.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2092.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2155.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2196.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2158.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2112.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2155.81it/s]\n",
            "20000it [00:09, 2144.35it/s]\n",
            "20000it [00:09, 2165.58it/s]\n",
            "20000it [00:09, 2168.08it/s]\n",
            "20000it [00:09, 2140.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2160.56it/s]\n",
            "20000it [00:09, 2170.55it/s]\n",
            "20000it [00:09, 2149.22it/s]\n",
            "20000it [00:09, 2096.93it/s]\n",
            "20000it [00:09, 2087.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:16, 1205.08it/s]\n",
            "20000it [00:16, 1207.45it/s]\n",
            "20000it [00:15, 1252.47it/s]\n",
            "20000it [00:16, 1248.91it/s]\n",
            "20000it [00:16, 1238.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2174.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2165.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2146.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2137.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2141.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2143.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2146.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2126.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2141.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2184.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2157.53it/s]\n",
            "20000it [00:09, 2096.55it/s]\n",
            "20000it [00:09, 2094.99it/s]\n",
            "20000it [00:09, 2114.95it/s]\n",
            "20000it [00:09, 2128.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2119.25it/s]\n",
            "20000it [00:09, 2129.10it/s]\n",
            "20000it [00:09, 2120.83it/s]\n",
            "20000it [00:09, 2149.65it/s]\n",
            "20000it [00:09, 2194.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:16, 1248.60it/s]\n",
            "20000it [00:15, 1266.08it/s]\n",
            "20000it [00:16, 1244.20it/s]\n",
            "20000it [00:16, 1234.46it/s]\n",
            "20000it [00:16, 1243.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm popularity\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2098.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2084.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2140.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2120.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2124.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm useraverage\n",
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2080.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2143.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2140.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2136.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2186.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2172.28it/s]\n",
            "20000it [00:09, 2177.72it/s]\n",
            "20000it [00:09, 2151.61it/s]\n",
            "20000it [00:09, 2193.29it/s]\n",
            "20000it [00:09, 2159.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:09, 2145.63it/s]\n",
            "20000it [00:09, 2156.74it/s]\n",
            "20000it [00:09, 2168.23it/s]\n",
            "20000it [00:09, 2170.28it/s]\n",
            "20000it [00:09, 2121.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm PMF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20000it [00:15, 1252.36it/s]\n",
            "20000it [00:15, 1251.52it/s]\n",
            "20000it [00:16, 1229.27it/s]\n",
            "20000it [00:16, 1232.69it/s]\n",
            "20000it [00:15, 1272.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq3jt70qIJyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to display the results for all the recommenders in Q1, Q2, Q3 (using cosine similarity) and Q4 on RMSE, P@k, and R@k.\n",
        "def result(metrics):\n",
        "    print('CrossValidation Metric: {}'.format(metrics[0]))\n",
        "    for algo, k in metrics[1].items():\n",
        "        print('Recommenders: {},  Mean:{:.4f}'.format(algo,k[1]))\n",
        "        print('Confidence Interval:({:.4f},{:.4f})\\n'.format(k[2],k[3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFvh6ozqIskX",
        "colab_type": "code",
        "outputId": "14343fb8-20bf-444f-a06f-c0dd385d4fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "metrics = [('RMSE',results_RMSE),('P@K',results_patk),('R@K',results_ratk)]\n",
        "for pair in metrics:\n",
        "    result(pair)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CrossValidation Metric: RMSE\n",
            "Recommenders: popularity,  Mean:3.1591\n",
            "Confidence Interval:(3.1393,3.1789)\n",
            "\n",
            "Recommenders: useraverage,  Mean:1.0437\n",
            "Confidence Interval:(1.0289,1.0585)\n",
            "\n",
            "Recommenders: item-cosine,  Mean:1.0201\n",
            "Confidence Interval:(1.0068,1.0333)\n",
            "\n",
            "Recommenders: user-cosine,  Mean:1.0174\n",
            "Confidence Interval:(1.0090,1.0257)\n",
            "\n",
            "Recommenders: PMF,  Mean:0.9493\n",
            "Confidence Interval:(0.9311,0.9675)\n",
            "\n",
            "CrossValidation Metric: P@K\n",
            "Recommenders: popularity,  Mean:0.5506\n",
            "Confidence Interval:(0.4054,0.6957)\n",
            "\n",
            "Recommenders: useraverage,  Mean:0.4736\n",
            "Confidence Interval:(0.3420,0.6053)\n",
            "\n",
            "Recommenders: item-cosine,  Mean:0.5322\n",
            "Confidence Interval:(0.3837,0.6807)\n",
            "\n",
            "Recommenders: user-cosine,  Mean:0.5558\n",
            "Confidence Interval:(0.4096,0.7021)\n",
            "\n",
            "Recommenders: PMF,  Mean:0.5566\n",
            "Confidence Interval:(0.4127,0.7006)\n",
            "\n",
            "CrossValidation Metric: R@K\n",
            "Recommenders: popularity,  Mean:0.4841\n",
            "Confidence Interval:(0.3671,0.6010)\n",
            "\n",
            "Recommenders: useraverage,  Mean:0.4413\n",
            "Confidence Interval:(0.3293,0.5533)\n",
            "\n",
            "Recommenders: item-cosine,  Mean:0.4750\n",
            "Confidence Interval:(0.3536,0.5964)\n",
            "\n",
            "Recommenders: user-cosine,  Mean:0.4863\n",
            "Confidence Interval:(0.3694,0.6031)\n",
            "\n",
            "Recommenders: PMF,  Mean:0.4862\n",
            "Confidence Interval:(0.3681,0.6044)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ndWFEgUzdu4"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjgRtqjCPvpj",
        "colab_type": "text"
      },
      "source": [
        "**Popularity cannot be evaluated by RMSE**, since the popularity is the fraction of people who have rated the movie that liked the movie and it falls in the range of (0,1) rather than value between [1,5]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNq4pU85R9Zk",
        "colab_type": "text"
      },
      "source": [
        "###(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLmHtDifSCfp",
        "colab_type": "text"
      },
      "source": [
        "PMF algorithm performs best for RMSE and P@K; user-cosine performs best for R@K, but PMF also performs very well.<br>\n",
        "PMF is best since it generates an approximation initial matrix and then to be optimized with loss function and hyparameter tuning. Popularity based recommendations only recommend the most popular items but not recommend items based on the user's likes. User-cosine and item-cosine are very regular methods. In our problem, since the number of item is more than the number of users, the user-cosine is more robust than the item-cosine; User average is also a very regular method that simply averages the user's ratings for other items, which may not be general enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvKxdELZijXs",
        "colab_type": "text"
      },
      "source": [
        "###(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLgW2RiqjDKG",
        "colab_type": "text"
      },
      "source": [
        "Not exactly. Generally, good RMSE represents good recommondations. But RMSE attaches equal emphasis on high and low ratings while the ranking matrices attach more importance on the higher ranking items. So good performance on ranking metrics doesn't imply good performance on RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wkx8GW4wzdu8"
      },
      "source": [
        "## Q6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HnLcDctYzdu9"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F16agjyHzdu_",
        "outputId": "cfe2be91-947c-4e7a-e054-ed68a0eda56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
        "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
        "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
        "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')\n",
        "\n",
        "moviesDF.head()"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieID</th>\n",
              "      <th>movieTitle</th>\n",
              "      <th>releaseDate</th>\n",
              "      <th>videoReleaseDate</th>\n",
              "      <th>IMDbURL</th>\n",
              "      <th>unknown</th>\n",
              "      <th>action</th>\n",
              "      <th>adventure</th>\n",
              "      <th>animation</th>\n",
              "      <th>childrens</th>\n",
              "      <th>comedy</th>\n",
              "      <th>crime</th>\n",
              "      <th>documentary</th>\n",
              "      <th>drama</th>\n",
              "      <th>fantasy</th>\n",
              "      <th>filmNoir</th>\n",
              "      <th>horror</th>\n",
              "      <th>musical</th>\n",
              "      <th>mystery</th>\n",
              "      <th>romance</th>\n",
              "      <th>sciFi</th>\n",
              "      <th>thriller</th>\n",
              "      <th>war</th>\n",
              "      <th>western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>01-Jan-1995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieID         movieTitle  releaseDate  ...  thriller war  western\n",
              "0        1   Toy Story (1995)  01-Jan-1995  ...         0   0        0\n",
              "1        2   GoldenEye (1995)  01-Jan-1995  ...         1   0        0\n",
              "2        3  Four Rooms (1995)  01-Jan-1995  ...         1   0        0\n",
              "3        4  Get Shorty (1995)  01-Jan-1995  ...         0   0        0\n",
              "4        5     Copycat (1995)  01-Jan-1995  ...         1   0        0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C8IqEsUrZ_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_matrix = dataPreprocessor(rating_df,num_users,num_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua1_lAtnsGEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_similarity = SimBasedRecSys.cosine(train_matrix.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6q6dlHhsLX7",
        "colab_type": "code",
        "outputId": "59a74895-cdf8-4395-f413-6c30210bdcdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Choose movieID 19, 54, 128\n",
        "print(\"Three not-so-popular movies: {}, {}, {}\".format(moviesDF.iloc[18][1], moviesDF.iloc[53][1], moviesDF.iloc[127][1]))\n",
        "print(\"\\n\")\n",
        "for i in [18,53,127]:\n",
        "    print(\"The similar movies of {}:\".format(moviesDF.iloc[i][1]))\n",
        "    print(list(map(lambda x:moviesDF.iloc[x][1],item_similarity[i].argsort()[::-1][1:6])),\"\\n\")"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Three not-so-popular movies: Antonia's Line (1995), Outbreak (1995), Supercop (1992)\n",
            "\n",
            "\n",
            "The similar movies of Antonia's Line (1995):\n",
            "['Cold Comfort Farm (1995)', 'Postino, Il (1994)', 'Secrets & Lies (1996)', 'Breaking the Waves (1996)', 'Lone Star (1996)'] \n",
            "\n",
            "The similar movies of Outbreak (1995):\n",
            "['Firm, The (1993)', 'Die Hard 2 (1990)', 'Clear and Present Danger (1994)', 'Client, The (1994)', 'Tombstone (1993)'] \n",
            "\n",
            "The similar movies of Supercop (1992):\n",
            "['Rumble in the Bronx (1995)', \"Jackie Chan's First Strike (1996)\", 'Desperado (1995)', 'Die Hard: With a Vengeance (1995)', 'From Dusk Till Dawn (1996)'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnRDOuH4zdvF"
      },
      "source": [
        "### (b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEM0Vg-gwQxb",
        "colab_type": "text"
      },
      "source": [
        "From the result we can see these similarities are reasonable. These similarities are generated by users who rated both films, and by using item-item cosine similarity.<br>\n",
        "From the examples above, I chose three not-so-popular movies, **Antonia's Line, Outbreak** and **Supercop**, and got 5 similar movies for each of them. For example, **Supercop was a kind of Hong Kong action comedy film and Jackie Chan, acting as a policaman was the main actor**, the similar movies like **Rumble in the Bronx**, which was action-adventure film acted by Jacie Chan (also acted a policeman); **Jackie Chan's First Strike**, a Hong Kong action comedy film acted by Jackie Chan; **Desperado** is an American action film. In all, the similarity makes sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QiSiG2UrzdvK"
      },
      "source": [
        "## Q7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sH63iq22zdvK"
      },
      "source": [
        "### (a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeUK2ZR5zdvM",
        "outputId": "3cead953-ee21-4e49-c673-09d02ffddf8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "data = (train_matrix!=0).sum(1)\n",
        "plt.hist(data,bins='auto')\n",
        "plt.title('Number of Ratings per User')\n",
        "plt.show()"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JnzfaggfTly",
        "colab_type": "code",
        "outputId": "7e832ef6-69cb-4ccf-a891-8b5c36bc3352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.average(data))\n",
        "print(np.median(data))"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106.04453870625663\n",
            "65.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VMsocVeOzGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a threshold\n",
        "threshold = 106"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJUqBpcPqPy8",
        "colab_type": "text"
      },
      "source": [
        "Choose the **average number of rating** of per user, since the average rating is larger than median, this threshold can divides users with few ratings and those with a moderate to large number of ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPhaUgGjRTMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Above_usid = [i for i,val in enumerate(data.tolist()) if val >= threshold]\n",
        "Below_usid = [i for i,val in enumerate(data.tolist()) if val < threshold]\n",
        "\n",
        "Above_threshold = rating_df[rating_df['userID'].isin(Above_usid)]\n",
        "Below_threshold = rating_df[rating_df['userID'].isin(Below_usid)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYgc6xOrR-Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CrossValidation_Q7(object):\n",
        "    def __init__(self, metric, criteria, cdata_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR,criteria)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def _getData(data_path,criteria):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            test_set = test_set[test_set['userID'].isin(criteria)]\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sanFiPAHaCik",
        "colab_type": "code",
        "outputId": "9e8ca23d-c110-4ed6-b082-37cd2caa0140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "algorithm_instances_Q7 = [item_cosine_recsys, \n",
        "                          user_cosine_recsys]\n",
        "cv_RMSE_Above = CrossValidation_Q7('RMSE',Above_usid)\n",
        "cv_RMSE_Below = CrossValidation_Q7('RMSE',Below_usid)\n",
        "results_Above = cv_RMSE_Above.run(algorithm_instances_Q7, num_users, num_items, k=5)\n",
        "results_Below = cv_RMSE_Below.run(algorithm_instances_Q7, num_users, num_items, k=5)"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7808it [00:03, 2252.51it/s]\n",
            "8010it [00:03, 2250.48it/s]\n",
            "7348it [00:03, 2246.40it/s]\n",
            "7388it [00:03, 2285.27it/s]\n",
            "7458it [00:03, 2279.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7808it [00:03, 2216.18it/s]\n",
            "8010it [00:03, 2250.24it/s]\n",
            "7348it [00:03, 2284.15it/s]\n",
            "7388it [00:03, 2257.99it/s]\n",
            "7458it [00:03, 2281.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm item-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12192it [00:05, 2192.35it/s]\n",
            "11990it [00:05, 2218.25it/s]\n",
            "12652it [00:05, 2208.38it/s]\n",
            "12565it [00:05, 2188.78it/s]\n",
            "12421it [00:05, 2207.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing algorithm user-cosine\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12192it [00:05, 2219.72it/s]\n",
            "11990it [00:05, 2227.59it/s]\n",
            "12652it [00:05, 2208.93it/s]\n",
            "12565it [00:05, 2194.57it/s]\n",
            "12421it [00:05, 2121.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUzQxQXAbCq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printresult_Q7(results):\n",
        "    for k,v in results.items():\n",
        "        print(\"The average and CI of RMSE for {} is : [{:.4f}, {}]\".format(k, results[k][1], results[k][2:4]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAecGRfvbao2",
        "colab_type": "code",
        "outputId": "6a3fef34-3ab7-44e9-e8ff-07584ff140a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Above threshold {} of liked items: \". format(threshold))\n",
        "printresult_Q7(results_Above)"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Above threshold 106 of liked items: \n",
            "The average and CI of RMSE for item-cosine is : [1.0217, [1.0106562109408526, 1.0328392265789688]]\n",
            "The average and CI of RMSE for user-cosine is : [1.0195, [1.0107669126319836, 1.028270796229668]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w-KdZC_bz8u",
        "colab_type": "code",
        "outputId": "b932514e-aba7-4f6f-a0d8-2a3e02d023c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Below threshold {} of liked items: \". format(threshold))\n",
        "printresult_Q7(results_Below)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Below threshold 106 of liked items: \n",
            "The average and CI of RMSE for item-cosine is : [1.0183, [1.002553678101927, 1.0339823097402652]]\n",
            "The average and CI of RMSE for user-cosine is : [1.0156, [1.0040561274184303, 1.0272105049198967]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7O0iFMFgg95",
        "colab_type": "text"
      },
      "source": [
        "From the results above we can see that both user-user and item-item collaborative filtering perform better when users whose number of rating are **below the threshold** 106. <br>\n",
        "From the histgram and the median of the number of ratings per user, since I chose the average ratings 106, it leads to the more users and more items below the threshold. When there are more data to estimate, the results should be more robust."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "id": "G2V2BXb-zdvQ"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjWEiRzezdvR",
        "colab": {}
      },
      "source": [
        "# Constants for validation only\n",
        "ROW_NUM = 943\n",
        "COL_NUM = 1682\n",
        "RATING_COL = 'rating'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mqZ3DOSHzdvV"
      },
      "source": [
        "### dataPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A4jypcIRzdvY",
        "colab": {}
      },
      "source": [
        "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
        "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
        "    try:\n",
        "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    except:\n",
        "        print('dataPreprocessor function has error')\n",
        "        return\n",
        "    try:\n",
        "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return validation_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_Tc_IVazdvd",
        "colab": {}
      },
      "source": [
        "validation_df = validateDataPreprocessor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4_PmoIrWzdvf"
      },
      "source": [
        "## Baseline Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zGA1yZ9hzdvf"
      },
      "source": [
        "### Popularity Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O_ySapEazdvg",
        "colab": {}
      },
      "source": [
        "def validatePopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    popularity_recsys = BaseLineRecSys('popularity')\n",
        "    try:\n",
        "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except Exception as e:        \n",
        "        print('popularity function has error')\n",
        "        print(e)\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = popularity_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TyCJ1Be0zdvi",
        "outputId": "9cfa0672-0e23-4680-e829-995aa230a76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "validatePopularityRecSys()"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4g1wwQpxzdvp"
      },
      "source": [
        "### User Average Based Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K1KASm63zdvp",
        "colab": {}
      },
      "source": [
        "def validateUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
        "    useraverage_recsys = BaseLineRecSys('useraverage')\n",
        "    try:\n",
        "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print('useraverage function has error')\n",
        "        return\n",
        "    try:\n",
        "        predictionMatrix = useraverage_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5A36VedIzdvs",
        "outputId": "90b0a907-9851-47d1-dc67-1cf18c99ae51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "validateUserAverRecSys()"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated 0 users\n",
            "calculated 100 users\n",
            "calculated 200 users\n",
            "calculated 300 users\n",
            "calculated 400 users\n",
            "calculated 500 users\n",
            "calculated 600 users\n",
            "calculated 700 users\n",
            "calculated 800 users\n",
            "calculated 900 users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlxJxooBzdvx"
      },
      "source": [
        "## Similary Based Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cvmIFAXXzdvy"
      },
      "source": [
        "### Euclidean Similarity Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z74E1PMRzdvy",
        "colab": {}
      },
      "source": [
        "def validateEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qqzEUppEzdv4",
        "colab": {}
      },
      "source": [
        "validateEuclidean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UnBQxFEPzdv6"
      },
      "source": [
        "### Customized Similarity Function (test somethingelse function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mPpRR_hjzdv6",
        "colab": {}
      },
      "source": [
        "def validateCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
        "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
        "    try:\n",
        "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
        "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
        "        assert(np.any(sim_matrix <= 1)),\\\n",
        "               \"Exist similarity value that is not less or equal to 1.\"\n",
        "    except Exception as e:\n",
        "        print(e) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4uGIWOS7zdv8",
        "colab": {}
      },
      "source": [
        "validateCustomizedSim()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DMKOOB6mzdwB"
      },
      "source": [
        "### User-User Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t_V0gdBTzdwB",
        "colab": {}
      },
      "source": [
        "def validateUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KkausxHizdwE",
        "colab": {}
      },
      "source": [
        "validateUUSimBasedRecSys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1IAGUMvwzdwH"
      },
      "source": [
        "### Item-Item Similarity Based Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-j6pDB3zdwH",
        "colab": {}
      },
      "source": [
        "def validateIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
        "    try:\n",
        "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
        "    except:\n",
        "        print(\"Got error when instantiate SimBasedRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        predictionMatrix = user_cosine_recsys.getModel()\n",
        "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
        "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
        "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TjAlZnpYzdwK",
        "colab": {}
      },
      "source": [
        "validateIISimBasedRecSys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FYo97yYTCKbI"
      },
      "source": [
        "### Probabilistic Matrix Factorization Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rB1_H8mxzdwO",
        "colab": {}
      },
      "source": [
        "def validatePMFRecSys(validation_df=validation_df):\n",
        "    try:\n",
        "        pmf = PMFRecSys()\n",
        "        pmf.set_params({\"num_feat\": 10, \"epsilon\": 1, \"_lambda\": 0.1, \"momentum\": 0.8, \"maxepoch\": 1, \"num_batches\": 100,\n",
        "                \"batch_size\": 1000, 'test_mode':True})\n",
        "        pmf.predict_all(rating_df, ROW_NUM, COL_NUM)\n",
        "    except:\n",
        "        print(\"Got error when instantiate PMFRecSys\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        pmf.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
        "        W_item, W_user = pmf.w_Item, pmf.w_User\n",
        "        assert(W_item.shape == (COL_NUM+1, 10) and W_user.shape == (ROW_NUM+1, 10)),\\\n",
        "        \"Shape of w_Item and W_User doesn't match predefined shape\"\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BW82XMfdzdwQ",
        "colab": {}
      },
      "source": [
        "validatePMFRecSys(validation_df=validation_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ldve7N_0DRF4",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}